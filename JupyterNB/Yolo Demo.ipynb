{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b138bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "14\n",
      "14\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "6\n",
      "17\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "1\n",
      "11\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "27\n",
      "26\n",
      "26\n",
      "26\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# create a while loop to get the frames of our webcam\n",
    "# arg 0 - for the camera connected to the PC\n",
    "# cap = cv2.VideoCapture(0) \n",
    "\n",
    "\n",
    "#width,height,Target\n",
    "whT=320\n",
    "\n",
    "confThreshold = 0.5\n",
    "\n",
    "#the lower this is the more intensive it will be in elminating overlapping\n",
    "nms_threshold = 0.3\n",
    "\n",
    "# To run the Yolo3 model\n",
    "# Yolo3 is trained on the Coco dataset\n",
    "# classes = ['','',''] likewise\n",
    "# But since it's a big list, to get the names of the classes(80 different classes),\n",
    "classesFile = 'coco.names'\n",
    "classNames = []\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "# to check if the extraction is correct\n",
    "# print(classNames)\n",
    "# print(len(classNames))\n",
    "\n",
    "# importing the model files\n",
    "# 2 main components (In Tensorflow save model method both of these files are compiled together)\n",
    "# 1.configurations file - parameters like learning rate,maximum batches,steps and individual convolutional layers and their params like the number of filters, strides, pads, activation functions (architecture of the network)\n",
    "# 2.weights file -\n",
    "# the fps is a tradeoff with the image pixel size\n",
    "# YOLOv320 - 45fps - general purpose\n",
    "# YOLOtiny - 220fps (trade off becuase accuracy will go down(less detectionn)) -  raspberry ppie/jetson nano\n",
    "# loading the files,\n",
    "\n",
    "#good for NVDIA GPU with all necessary SW installed\n",
    "modelConfiguration = 'yolov3.cfg'\n",
    "modelWeights = 'yolov3.weights'\n",
    "\n",
    "#Raspberry pie,Jetson Nano\n",
    "# modelConfiguration = 'yolov3-tiny.cfg'\n",
    "# modelWeights = 'yolov3-tiny.weights'\n",
    "\n",
    "# create the network\n",
    "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "# declare opencv as the backend,usage of CPU\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "def findObjects(output,img):\n",
    "    #height, width,channels\n",
    "    hT,wT,cT = img.shape\n",
    "    #3 differect list to store\n",
    "    # (whenever we find a good object detection, we will put them in these lists)\n",
    "\n",
    "    #bounding box will contain width height(x and y)\n",
    "    bbox = []\n",
    "\n",
    "    #class Ids and their confidence value\n",
    "    classIds = []\n",
    "    confs = []\n",
    "\n",
    "    #looping\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            #remove first 5 elements find the value of the height value\n",
    "            scores = det[5:]\n",
    "            #index\n",
    "            classId = np.argmax(scores)\n",
    "            #value of that index\n",
    "            confidence = scores[classId]\n",
    "\n",
    "            #filtering object\n",
    "            if confidence > confThreshold:\n",
    "                #save width,height,x,y(are in decimals so we have to multiple them by our actual image size)\n",
    "                w,h=int(det[2]*wT),int(det[3]*hT)\n",
    "                #the center point(divide by 2 and substract)\n",
    "                x,y=int(det[0]*wT - w/2) , int(det[1]*hT - h/2)\n",
    "                bbox.append([x,y,w,h])\n",
    "                classIds.append(classId)\n",
    "                confs.append(float(confidence))\n",
    "    print(len(bbox))\n",
    "\n",
    "    #to remove overlapping bounding boxes(non maximum surpression)\n",
    "    #by finding and picking the maximum confidence value box\n",
    "    #output are the indices of the bboxes to keep\n",
    "    indices = cv2.dnn.NMSBoxes(bbox,confs,confThreshold,nms_threshold)\n",
    "    # prinnt(indices)\n",
    "\n",
    "    #ploting the remaining indices in a loop\n",
    "    for i in indices:\n",
    "        #to remove the extra bracket\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        #extract x,y,width,height\n",
    "        x,y,w,h = box[0],box[1],box[2],box[3]\n",
    "        #drawing the box\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "        #print name and confidence level\n",
    "        cv2.putText(img,f'{classNames[classIds[i]].upper()} {int(confs[i]*100)}%',\n",
    "                    (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,255),2)\n",
    "\n",
    "# for screen capturing\n",
    "from mss import mss\n",
    "import cv2\n",
    "from PIL import Image #PILLOW\n",
    "import numpy as np\n",
    "\n",
    "mon = {'top':100,'left':100,'width':1600,'height':1024}\n",
    "sct = mss()\n",
    "        \n",
    "        \n",
    "while True:\n",
    "    \n",
    "    sct_img = sct.grab(mon) #grab the monitor\n",
    "    im = Image.frombytes('RGB',(sct_img.size.width,sct_img.size.height),sct_img.rgb) #what kind of image we need (we need an image that can be shown using openCV)\n",
    "    \n",
    "    #change RGB to BGR\n",
    "    img = cv2.cvtColor(np.array(im),cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#     cv2.imshow('test',np.array(img_bgr)) #show transformed in a numpy array\n",
    "    \n",
    "#     #define a bp(breakpoint)\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "    \n",
    "    \n",
    "    # will give us the image (and tell us if it was successful or not)\n",
    "#     success, img = cap.read()\n",
    "\n",
    "    # run forward pass on our network using our webcam image\n",
    "    # inputting out image from webcam to network(cannot use the plain image-convert image to blob)\n",
    "    blob = cv2.dnn.blobFromImage(img,1/255,(whT,whT),[0,0,0],1,crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    #all the available layers\n",
    "    layerNames = net.getLayerNames()\n",
    "    #to extract only the output layers\n",
    "    #loops\n",
    "    outputNames = [layerNames[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    # print(outputNames)\n",
    "\n",
    "    #to send the image as a forward pass to the network and get the output from the above layers\n",
    "    outputs = net.forward(outputNames)\n",
    "    # print(len(outputs))\n",
    "    # print(type(outputs[0]))\n",
    "\n",
    "    #like a matrix of 300 rows x 85 cols (300 bounding boxes)\n",
    "    # print(outputs[0].shape)\n",
    "    # like a matrix of 1200 rows x 85 cols(1200 bounding boxes)\n",
    "    # print(outputs[1].shape)\n",
    "    # like a matrix of 4800 rows x 85 cols(4800 bounding boxes)\n",
    "    # print(outputs[2].shape)\n",
    "    #85 - 1center x(cx),2center y(cy),3width (w),4height (h),5 confidence level,rest(probabilities of the object predictions)\n",
    "    #Eg if 3=0.9 in coco.name 3rd element (object inside the box is a car)\n",
    "    # print(outputs[0][0])\n",
    "\n",
    "    #go through all the boxes of 4800,1200,300 and see if the probability is good enough\n",
    "    #if it is keep it and plot it or else remove it\n",
    "    # go inside the output array and extract box info,probability info,object id\n",
    "    findObjects(outputs,img)\n",
    "\n",
    "\n",
    "    # outputing the bounding boxes\n",
    "\n",
    "    # Window name, and the image we want to display\n",
    "    cv2.imshow('Image', img)\n",
    "    # the time we want to delay it (by running code up to here, the camera will be turned on)\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ceb072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
